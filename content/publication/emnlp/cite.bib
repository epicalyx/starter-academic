@inproceedings{sawhney-etal-2020-voltage,
    title = "{V}ol{TAGE}: Volatility Forecasting via Text Audio Fusion with Graph Convolution Networks for Earnings Calls",
    author = "Sawhney, Ramit  and
      Khanna, Piyush  and
      Aggarwal, Arshiya  and
      Jain, Taru  and
      Mathur, Puneet  and
      Shah, Rajiv Ratn",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.643",
    doi = "10.18653/v1/2020.emnlp-main.643",
    pages = "8001--8013",
    abstract = "Natural language processing has recently made stock movement forecasting and volatility forecasting advances, leading to improved financial forecasting. Transcripts of companies{'} earnings calls are well studied for risk modeling, offering unique investment insight into stock performance. However, vocal cues in the speech of company executives present an underexplored rich source of natural language data for estimating financial risk. Additionally, most existing approaches ignore the correlations between stocks. Building on existing work, we introduce a neural model for stock volatility prediction that accounts for stock interdependence via graph convolutions while fusing verbal, vocal, and financial features in a semi-supervised multi-task risk forecasting formulation. Our proposed model, VolTAGE, outperforms existing methods demonstrating the effectiveness of multimodal learning for volatility prediction.",
}
